{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from itertools import product\n",
    "from pathlib import Path\n",
    "\n",
    "import geojson\n",
    "import holidays\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyproj\n",
    "from shapely import wkb\n",
    "from shapely.geometry import shape\n",
    "from shapely.ops import transform\n",
    "from tqdm import tqdm\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "pd.options.plotting.backend = \"plotly\"\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.max_rows\", 20)\n",
    "pd.set_option(\"display.width\", 500)\n",
    "pd.set_option(\"display.expand_frame_repr\", False)\n",
    "\n",
    "np.random.seed(2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_mem_usage(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"iterate through all the columns of a dataframe and modify the data type\n",
    "    to reduce memory usage.\n",
    "    \"\"\"\n",
    "    start_mem = df.memory_usage().sum() / 1024**2\n",
    "    print(\"Memory usage of dataframe is {:.2f} MB\".format(start_mem))\n",
    "\n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtype\n",
    "\n",
    "        if col_type != object:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == \"int\":\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df.loc[:, col] = df.loc[:, col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df.loc[:, col] = df.loc[:, col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df.loc[:, col] = df.loc[:, col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df.loc[:, col] = df.loc[:, col].astype(np.int64)\n",
    "            elif str(col_type)[:5] == \"float\":\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df.loc[:, col] = df.loc[:, col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df.loc[:, col] = df.loc[:, col].astype(np.float32)\n",
    "                else:\n",
    "                    df.loc[:, col] = df.loc[:, col].astype(np.float64)\n",
    "        else:\n",
    "            df[col] = df[col].astype(\"category\")\n",
    "\n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    print(\"Memory usage after optimization is: {:.2f} MB\".format(end_mem))\n",
    "    print(\"Decreased by {:.1f}%\".format(100 * (start_mem - end_mem) / start_mem))\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Предобработка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Исходный датасет\n",
    "\n",
    "- timestamp – временная метка публикации с точностью до часа\n",
    "- lon, lat – координаты геопозиции с округлением до полигона 250х250 метров (географические долгота и широта, соответственно)\n",
    "- likescount – количество отметок «лайк» у публикации\n",
    "- commentscount – количество комментариев у публикации\n",
    "- symbols_cnt – общее количество символов в публикации\n",
    "- words_cnt – количество слов (осмысленных, не считая спецсимволов и прочую метаинформацию)\n",
    "- hashtags_cnt – количество хештегов \n",
    "- mentions_cnt – количество упоминаний других пользователей\n",
    "- links_cnt – количество ссылок\n",
    "- emoji_cnt – количество эмодзи"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = reduce_mem_usage(pd.read_csv(\"./../source/train_data_v2.csv\"))\n",
    "\n",
    "print(train_df.shape)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Преобразуем координаты\n",
    "\n",
    "- переводим координаты в WKB формат;\n",
    "- добавляем идентификаторы полигонов;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"polygon_center_wkb\"] = train_df[\"point\"].apply(bytes.fromhex)\n",
    "train_df[\"polygon_id\"] = train_df.groupby(\"polygon_center_wkb\").ngroup()\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- создаем справчник полигонов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wgs84 = pyproj.CRS(\"EPSG:4326\")\n",
    "utm = pyproj.CRS(\"EPSG:3857\")\n",
    "\n",
    "wgs84_utm_project = pyproj.Transformer.from_crs(wgs84, utm, always_xy=True).transform\n",
    "utm_wgs84_project = pyproj.Transformer.from_crs(utm, wgs84, always_xy=True).transform\n",
    "\n",
    "\n",
    "def center_to_polygon(wgs84_point_wkb, d=125):\n",
    "    wgs84_polygon = transform(\n",
    "        utm_wgs84_project,\n",
    "        transform(wgs84_utm_project, wkb.loads(wgs84_point_wkb)).buffer(distance=d, cap_style=3),\n",
    "    )\n",
    "    return wgs84_polygon.wkb\n",
    "\n",
    "\n",
    "with open(\"./../source/spe_geometry.geojson\") as f_src:\n",
    "    spe_polygon = shape(geojson.load(f_src))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "polygons_df = train_df.groupby(\"polygon_center_wkb\", as_index=False).first()[\n",
    "    [\"polygon_id\", \"lon\", \"lat\", \"polygon_center_wkb\"]\n",
    "]\n",
    "polygons_df[\"polygon_wkb\"] = polygons_df[\"polygon_center_wkb\"].apply(center_to_polygon)\n",
    "polygons_df[\"polygon_in_st_petersburg\"] = (\n",
    "    polygons_df[\"polygon_center_wkb\"].apply(lambda point: spe_polygon.contains(wkb.loads(point))).astype(int)\n",
    ")\n",
    "\n",
    "polygons_df = polygons_df.astype(\n",
    "    {\n",
    "        \"polygon_id\": \"int16\",\n",
    "        \"polygon_center_wkb\": \"object\",\n",
    "        \"polygon_wkb\": \"object\",\n",
    "        \"polygon_in_st_petersburg\": \"int8\",\n",
    "    }\n",
    ")\n",
    "\n",
    "print(polygons_df.shape)\n",
    "polygons_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "polygons_df.groupby(\"polygon_in_st_petersburg\").agg(polygons_count=(\"polygon_id\", \"count\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Преобразуем временные метки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_harmonic_features_cos(value, period=12):\n",
    "    value *= 2 * np.pi / period\n",
    "    return np.cos(value)\n",
    "\n",
    "\n",
    "def make_harmonic_features_sin(value, period=12):\n",
    "    value *= 2 * np.pi / period\n",
    "    return np.sin(value)\n",
    "\n",
    "\n",
    "russia_holidays = holidays.RU()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calendar_df = pd.date_range(\"2019-01-01T00:00:00\", \"2020-02-29T23:00:00\", freq=\"1H\").to_frame(\n",
    "    index=False, name=\"event_dttm\"\n",
    ")\n",
    "\n",
    "calendar_df[\"event_ts\"] = calendar_df[\"event_dttm\"].astype(np.int64) // 10**9\n",
    "calendar_df[\"event_time_id\"] = calendar_df.index\n",
    "\n",
    "calendar_df[\"year\"] = calendar_df[\"event_dttm\"].dt.year\n",
    "calendar_df[\"month\"] = calendar_df[\"event_dttm\"].dt.month\n",
    "calendar_df[\"day\"] = calendar_df[\"event_dttm\"].dt.day\n",
    "calendar_df[\"weekday\"] = calendar_df[\"event_dttm\"].dt.weekday\n",
    "calendar_df[\"hour\"] = calendar_df[\"event_dttm\"].dt.hour\n",
    "\n",
    "calendar_df[\"weekend\"] = calendar_df[\"event_dttm\"].dt.weekday // 4\n",
    "calendar_df[\"holidays\"] = calendar_df[\"event_dttm\"].apply(lambda x: int(x in russia_holidays))\n",
    "\n",
    "calendar_df[\"month_cos\"] = calendar_df[\"month\"].apply(lambda x: make_harmonic_features_cos(x, 12))\n",
    "calendar_df[\"month_sin\"] = calendar_df[\"month\"].apply(lambda x: make_harmonic_features_sin(x, 12))\n",
    "calendar_df[\"weekday_cos\"] = calendar_df[\"weekday\"].apply(lambda x: make_harmonic_features_cos(x, 7))\n",
    "calendar_df[\"weekday_sin\"] = calendar_df[\"weekday\"].apply(lambda x: make_harmonic_features_sin(x, 7))\n",
    "calendar_df[\"hour_cos\"] = calendar_df[\"hour\"].apply(lambda x: make_harmonic_features_cos(x, 24))\n",
    "calendar_df[\"hour_sin\"] = calendar_df[\"hour\"].apply(lambda x: make_harmonic_features_sin(x, 24))\n",
    "\n",
    "calendar_df = reduce_mem_usage(calendar_df.set_index([\"event_time_id\", \"event_ts\", \"event_dttm\"]).reset_index())\n",
    "\n",
    "print(calendar_df.shape)\n",
    "calendar_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"event_dttm < '2020-02-01': {calendar_df[calendar_df['event_dttm'] < '2020-02-01'].shape[0]}\")\n",
    "print(f\"event_dttm >= '2020-02-01': {calendar_df[calendar_df['event_dttm'] >= '2020-02-01'].shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.merge(calendar_df, how=\"left\", left_on=\"timestamp\", right_on=\"event_ts\")\n",
    "print(f\"Null in 'event_time_id' column: {train_df['event_time_id'].isnull().sum()}\")\n",
    "\n",
    "print(train_df.shape)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка фичей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posts_count_df = reduce_mem_usage(\n",
    "    train_df.groupby([\"polygon_id\", \"event_time_id\"], as_index=False).agg(\n",
    "        posts_count=(\"polygon_center_wkb\", \"count\")\n",
    "    )\n",
    ")\n",
    "\n",
    "print(posts_count_df.shape)\n",
    "posts_count_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posts_params_columns = [\n",
    "    \"likescount\",\n",
    "    \"commentscount\",\n",
    "    \"symbols_cnt\",\n",
    "    \"words_cnt\",\n",
    "    \"hashtags_cnt\",\n",
    "    \"mentions_cnt\",\n",
    "    \"links_cnt\",\n",
    "    \"emoji_cnt\",\n",
    "]\n",
    "\n",
    "# posts_params_aggregates = [\"min\", \"max\", \"sum\", \"median\", \"mean\", \"std\"]\n",
    "posts_params_aggregates = [\"mean\", \"std\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posts_params_df = reduce_mem_usage(\n",
    "    train_df.groupby([\"polygon_id\", \"event_time_id\"], as_index=False).agg(\n",
    "        {p: posts_params_aggregates for p in posts_params_columns}\n",
    "    )\n",
    ")\n",
    "posts_params_df.columns = [c for c, _ in posts_params_df.columns if c not in posts_params_columns] + [\n",
    "    f\"{c}_{s}\" for c, s in posts_params_df.columns if c in posts_params_columns\n",
    "]\n",
    "\n",
    "print(posts_params_df.shape)\n",
    "posts_params_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Формирование витрины"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mart_df = reduce_mem_usage(\n",
    "    polygons_df.loc[polygons_df[\"polygon_in_st_petersburg\"] == 1, [\"polygon_id\", \"lon\", \"lat\"]]\n",
    "    .merge(\n",
    "        calendar_df.drop(columns=[\"event_ts\", \"event_dttm\"]),\n",
    "        how=\"cross\",\n",
    "    )\n",
    "    .merge(posts_count_df, on=[\"polygon_id\", \"event_time_id\"], how=\"left\")\n",
    "    .merge(posts_params_df, on=[\"polygon_id\", \"event_time_id\"], how=\"left\")\n",
    "    .fillna({\"posts_count\": 0})\n",
    "    .astype({\"posts_count\": \"int\"})\n",
    "    .set_index([\"polygon_id\", \"event_time_id\"])\n",
    "    .reset_index()\n",
    ")\n",
    "mart_df.to_pickle(\"./_mart.pkl\")\n",
    "\n",
    "print(mart_df.shape)\n",
    "mart_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_series_lag_features(src_df: pd.DataFrame, col_names: list, lag_list: list) -> pd.DataFrame:\n",
    "    df = src_df.copy()\n",
    "\n",
    "    for col in tqdm(col_names):\n",
    "        for lag in lag_list:\n",
    "            df[f\"{col}_lag_{lag // 24}\"] = (\n",
    "                df.sort_values(by=[\"polygon_id\", \"event_time_id\"])\n",
    "                .groupby([\"polygon_id\"])[col]\n",
    "                .transform(lambda x: x.shift(lag))\n",
    "            )\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def get_series_roll_mean_features(\n",
    "    src_df: pd.DataFrame, col_names: list, lag_list: list, roll_list: list\n",
    ") -> pd.DataFrame:\n",
    "    df = src_df.copy()\n",
    "\n",
    "    for col in tqdm(col_names):\n",
    "        for lag in lag_list:\n",
    "            for roll in roll_list:\n",
    "                df[f\"{col}_lag_{lag // 24}_roll_{roll // 24}_mean\"] = (\n",
    "                    df.sort_values(by=[\"polygon_id\", \"event_time_id\"])\n",
    "                    .groupby([\"polygon_id\"])[f\"{col}_lag_{lag // 24}\"]\n",
    "                    .transform(lambda x: x.rolling(window=roll).mean())\n",
    "                )\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def get_series_roll_std_features(\n",
    "    src_df: pd.DataFrame, col_names: list, lag_list: list, roll_list: list\n",
    ") -> pd.DataFrame:\n",
    "    df = src_df.copy()\n",
    "\n",
    "    for col in tqdm(col_names):\n",
    "        for lag in lag_list:\n",
    "            for roll in roll_list:\n",
    "                df[f\"{col}_lag_{lag // 24}_roll_{roll // 24}_std\"] = (\n",
    "                    df.sort_values(by=[\"polygon_id\", \"event_time_id\"])\n",
    "                    .groupby([\"polygon_id\"])[f\"{col}_lag_{lag // 24}\"]\n",
    "                    .transform(lambda x: x.rolling(window=roll).std())\n",
    "                )\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mart_df = pd.read_pickle(\"./_mart.pkl\")\n",
    "\n",
    "mart_df = reduce_mem_usage(\n",
    "    get_series_lag_features(\n",
    "        mart_df,\n",
    "        [\"posts_count\"] + [f\"{a}_{b}\" for a, b in product(posts_params_columns, posts_params_aggregates)],\n",
    "        # lag_list=[28 * 24, 35 * 24, 42 * 24],\n",
    "        lag_list=[28 * 24],\n",
    "    )\n",
    ")\n",
    "mart_df.to_pickle(\"./_mart_1.pkl\")\n",
    "\n",
    "print(mart_df.shape)\n",
    "mart_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mart_df = pd.read_pickle(\"./_mart_1.pkl\")\n",
    "\n",
    "mart_df = reduce_mem_usage(\n",
    "    get_series_roll_mean_features(\n",
    "        mart_df,\n",
    "        [\"posts_count\"] + [f\"{a}_{b}\" for a, b in product(posts_params_columns, posts_params_aggregates)],\n",
    "        # lag_list=[28 * 24, 35 * 24, 42 * 24],\n",
    "        # roll_list=[8 * 24, 15 * 24, 22 * 24],\n",
    "        lag_list=[28 * 24],\n",
    "        roll_list=[15 * 24],\n",
    "    )\n",
    ")\n",
    "mart_df.to_pickle(\"./_mart_2.pkl\")\n",
    "\n",
    "print(mart_df.shape)\n",
    "mart_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mart_df = pd.read_pickle(\"./_mart_2.pkl\")\n",
    "\n",
    "mart_df = reduce_mem_usage(\n",
    "    get_series_roll_std_features(\n",
    "        mart_df,\n",
    "        [\"posts_count\"] + [f\"{a}_{b}\" for a, b in product(posts_params_columns, posts_params_aggregates)],\n",
    "        # lag_list=[28 * 24, 35 * 24, 42 * 24],\n",
    "        # roll_list=[8 * 24, 15 * 24, 22 * 24],\n",
    "        lag_list=[28 * 24],\n",
    "        roll_list=[15 * 24],\n",
    "    )\n",
    ")\n",
    "mart_df.to_pickle(\"./_mart_3.pkl\")\n",
    "\n",
    "print(mart_df.shape)\n",
    "mart_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mart_df = pd.read_pickle(\"./_mart_3.pkl\")\n",
    "\n",
    "mart_df = reduce_mem_usage(\n",
    "    mart_df[\n",
    "        [\n",
    "            col\n",
    "            for col in mart_df.columns\n",
    "            if col in polygons_df.columns\n",
    "            or col in calendar_df.columns\n",
    "            or col == \"posts_count\"\n",
    "            or \"_lag_\" in col\n",
    "            or \"_roll_\" in col\n",
    "        ]\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(mart_df.shape)\n",
    "mart_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка валидационного и тестового датасетов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_df = pd.read_csv(\"./../source/valid.csv\")\n",
    "\n",
    "valid_df[\"polygon_center_wkb\"] = valid_df[\"point\"].apply(bytes.fromhex)\n",
    "valid_df[\"event_ts\"] = valid_df[\"hour\"]\n",
    "valid_df[\"fact_posts_count\"] = valid_df[\"sum\"]\n",
    "\n",
    "valid_df = valid_df.merge(\n",
    "    polygons_df.loc[polygons_df[\"polygon_in_st_petersburg\"] == 1, [\"polygon_center_wkb\", \"polygon_id\"]],\n",
    "    how=\"inner\",\n",
    "    on=\"polygon_center_wkb\",\n",
    ").merge(calendar_df[[\"event_ts\", \"event_time_id\"]], how=\"inner\", on=\"event_ts\")[\n",
    "    [\"polygon_id\", \"event_time_id\", \"fact_posts_count\", \"error\"]\n",
    "]\n",
    "\n",
    "print(valid_df.shape)\n",
    "valid_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = reduce_mem_usage(pd.read_csv(\"./../source/test.csv\"))\n",
    "\n",
    "test_df[\"polygon_center_wkb\"] = test_df[\"point\"].apply(bytes.fromhex)\n",
    "test_df[\"event_ts\"] = test_df[\"hour\"]\n",
    "test_df[\"fact_posts_count\"] = test_df[\"sum\"]\n",
    "\n",
    "test_df = test_df.merge(\n",
    "    polygons_df.loc[polygons_df[\"polygon_in_st_petersburg\"] == 1, [\"polygon_center_wkb\", \"polygon_id\"]],\n",
    "    how=\"inner\",\n",
    "    on=\"polygon_center_wkb\",\n",
    ").merge(calendar_df[[\"event_ts\", \"event_time_id\"]], how=\"inner\", on=\"event_ts\")[\n",
    "    [\"polygon_id\", \"event_time_id\", \"fact_posts_count\", \"error\"]\n",
    "]\n",
    "\n",
    "print(test_df.shape)\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка обучающей выборки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "polygon_posts_df = mart_df.groupby(\"polygon_id\", as_index=False)[[\"posts_count\"]].sum()\n",
    "polygon_posts_df[\"decile\"] = pd.qcut(polygon_posts_df[\"posts_count\"], q=10, labels=range(10))\n",
    "\n",
    "polygon_sample_df = pd.concat(\n",
    "    [polygon_posts_df[polygon_posts_df[\"decile\"].eq(label)].sample(50) for label in range(10)]\n",
    ")\n",
    "\n",
    "mart_sample_df = mart_df.merge(polygon_sample_df[[\"polygon_id\"]], how=\"inner\", on=\"polygon_id\")\n",
    "\n",
    "print(mart_sample_df.shape)\n",
    "mart_sample_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Сохарнение результатов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path(\"./../data\")\n",
    "\n",
    "if not data_dir.exists():\n",
    "    data_dir.mkdir()\n",
    "\n",
    "polygons_path = Path(data_dir, \"polygons.pkl\")\n",
    "calendar_path = Path(data_dir, \"calendar.pkl\")\n",
    "\n",
    "mart_path = Path(data_dir, \"mart.pkl\")\n",
    "mart_sample_path = Path(data_dir, \"mart_sample.pkl\")\n",
    "\n",
    "valid_path = Path(data_dir, \"valid.pkl\")\n",
    "test_path = Path(data_dir, \"test.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "polygons_df.to_pickle(polygons_path)\n",
    "calendar_df.to_pickle(calendar_path)\n",
    "\n",
    "mart_df.to_pickle(mart_path)\n",
    "mart_sample_df.to_pickle(mart_sample_path)\n",
    "\n",
    "valid_df.to_pickle(valid_path)\n",
    "test_df.to_pickle(test_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Визуализация части витрины"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_pickle(mart_sample_path).plot(x=\"event_time_id\", y=\"posts_count\", color=\"polygon_id\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('.venv': poetry)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0d2b43afa4b906e126edc721c15637edc121f2ae012862e0c62380fa084b3ffa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
